{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import itertools\n",
    "import sys\n",
    "import json\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import pycocotools.mask as mask_util\n",
    "import io\n",
    "import contextlib\n",
    "from multiprocessing import Pool\n",
    "import pickle\n",
    "from scipy.stats import gmean\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_ANNS = \"../data/val_annot.json\"\n",
    "PATH_TO_PREDS = \"/scratch/shared/beegfs/prannay/ego4d_data/ckpt/results/traces_v2_all/vq_stats_val_{}.json.gz\"\n",
    "PATH_TO_DINO = \"/scratch/shared/beegfs/prannay/ego4d_data/ckpt/results/traces_v2_all/vq_stats_val_{}_dino_scores_all.pkl\"\n",
    "assert os.path.exists(PATH_TO_ANNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH_TO_ANNS, \"r\") as f:\n",
    "    anns = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED_IDXS = range(0, 200)\n",
    "path_to_preds = [PATH_TO_PREDS.format(i) for i in PRED_IDXS]\n",
    "assert all([os.path.exists(p) for p in path_to_preds])\n",
    "path_to_dinos = [PATH_TO_DINO.format(i) for i in PRED_IDXS]\n",
    "assert all([os.path.exists(p) for p in path_to_dinos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(path):\n",
    "    with gzip.open(path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    data = data['predictions']\n",
    "    # convert generic Dict[List] to List[Dict]\n",
    "    out_list = []\n",
    "    keys = sorted(data.keys())\n",
    "    for idx in range(len(data[keys[0]])):\n",
    "        save_dict = {k: data[k][idx] for k in keys}\n",
    "        save_dict['dataset_uid'] = save_dict['dataset_uids']\n",
    "        del save_dict['dataset_uids'] \n",
    "        out_list.append(save_dict)\n",
    "    return out_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dino(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        dino_data = pickle.load(f)\n",
    "    return dict(dino_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff809123acc74811bbd60266fc883309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with Pool(48) as p:\n",
    "    predictions_raw = list(tqdm(p.imap_unordered(preprocess_data, path_to_preds), total=len(path_to_preds)))\n",
    "# predictions_raw = []\n",
    "# for path_to_pred in tqdm(path_to_preds, total=len(path_to_preds)):\n",
    "#     # with gzip.open(path_to_pred, \"rt\") as f:\n",
    "#     predictions_raw.append(preprocess_data(path_to_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_raw = list(itertools.chain(*predictions_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de77e983f6fb4c02bbd84d264a55bc1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "duid2dino = {}\n",
    "for path_to_dino in tqdm(path_to_dinos, total=len(path_to_dinos)):\n",
    "    duid2dino.update(preprocess_dino(path_to_dino))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "8\n",
      "dict_keys(['groundtruth_response_tracks', 'predicted_bboxes', 'predicted_peaks', 'predicted_scores', 'predicted_trace_fnos', 'predicted_trace_scores', 'visual_crop', 'dataset_uid'])\n",
      "val_0000000000\n"
     ]
    }
   ],
   "source": [
    "print(type(predictions_raw[0]))\n",
    "print(len(predictions_raw[0]))\n",
    "print(predictions_raw[0].keys())\n",
    "print(predictions_raw[0]['dataset_uid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_duids = set([ann['dataset_uid'] for ann in anns if ann['clip_uid'] is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "22\n",
      "['val_0000000000', 'val_0000000001', 'val_0000000002', 'val_0000000003', 'val_0000000004']\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "duid2pred = {p['dataset_uid']: p for p in predictions_raw if p['dataset_uid'] in valid_duids}\n",
    "print(len(duid2pred))\n",
    "duid2gt = {ann['dataset_uid']: ann for ann in anns if ann['dataset_uid'] in duid2pred}\n",
    "print(len(duid2gt))\n",
    "duid2dino = {duid: duid2dino[duid] for duid in duid2pred}\n",
    "print(sorted(duid2gt.keys())[:5])\n",
    "print(len(duid2dino))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'duid2pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(duid2pred[\u001b[39m'\u001b[39m\u001b[39mval_0000000000\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mpredicted_scores\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m1\u001b[39m])\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(duid2dino[\u001b[39m'\u001b[39m\u001b[39mval_0000000000\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m1\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(softmax(duid2dino[\u001b[39m\"\u001b[39m\u001b[39mval_0000000000\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m \u001b[39m50.0\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'duid2pred' is not defined"
     ]
    }
   ],
   "source": [
    "print(duid2pred['val_0000000000']['predicted_scores'][1])\n",
    "print(duid2dino['val_0000000000'][1])\n",
    "print(softmax(duid2dino[\"val_0000000000\"][1] * 50.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_bboxes(x, cid, scores=None, dino_scores=None, score_func=np.mean, softmax_mul=0.0):\n",
    "    aid = 1\n",
    "    anns = []\n",
    "    if scores is not None:\n",
    "        for sc, d_sc, bb in zip(scores, dino_scores, x):\n",
    "            # make sure that d_sc is greater than eps\n",
    "            d_sc = np.maximum(d_sc, 1e-6)\n",
    "            if softmax_mul:\n",
    "                d_sc = softmax(d_sc * softmax_mul)\n",
    "            for s, ds, b in zip(sc, d_sc, bb):\n",
    "                bbox = [b['x1'], b['y1'], b['x2'] - b['x1'], b['y2'] - b['y1']]\n",
    "                bbox = [float(a) for a in bbox]\n",
    "                category_id = cid\n",
    "                image_id = b['fno']\n",
    "                ann_id = aid\n",
    "                score = s\n",
    "                anns.append({\n",
    "                    'bbox': bbox,\n",
    "                    'category_id': category_id,\n",
    "                    'image_id': image_id,\n",
    "                    'id': ann_id,\n",
    "                    'score': score_func([score, ds]),\n",
    "                    'area': bbox[2] * bbox[3],\n",
    "                })\n",
    "                aid += 1\n",
    "\n",
    "    else:\n",
    "        for bb in x:\n",
    "            bbox = [bb['x'], bb['y'], bb['width'], bb['height']]\n",
    "            bbox = [float(a) for a in bbox]\n",
    "            category_id = cid\n",
    "            image_id = bb['frame_number']\n",
    "            ann_id = aid\n",
    "            anns.append({\n",
    "                'bbox': bbox,\n",
    "                'category_id': category_id,\n",
    "                'image_id': image_id,\n",
    "                'id': ann_id,\n",
    "                'iscrowd': False,\n",
    "                'score': 1.0,\n",
    "                'area': bbox[2] * bbox[3],\n",
    "            })\n",
    "            aid += 1\n",
    "    return anns\n",
    "\n",
    "def construct_imgs(x, num_valid_frames):\n",
    "    fno = x[0]['frame_number']\n",
    "    h, w = x[0]['original_height'], x[0]['original_width']\n",
    "    imgs = []\n",
    "    for i in range(num_valid_frames):\n",
    "        imgs.append({\n",
    "            'file_name': \"n/a\",\n",
    "            'height': h,\n",
    "            'width': w,\n",
    "            'id': fno + i\n",
    "        })\n",
    "    return imgs\n",
    "\n",
    "def get_ious(gt_anns, pred_anns, imgs, cid):\n",
    "    from pycocotools.coco import COCO\n",
    "    from pycocotools.cocoeval import COCOeval\n",
    "    categories = [{'id': cid, 'name': f'target of val_{cid:10d}'}]\n",
    "    with contextlib.redirect_stdout(io.StringIO()):\n",
    "        gt = COCO()\n",
    "        pred = COCO()\n",
    "        gt.dataset = {'images': imgs, 'annotations': gt_anns, 'categories': categories}\n",
    "        pred.dataset = {'images': imgs, 'annotations': pred_anns, 'categories': categories}\n",
    "        gt.createIndex()\n",
    "        pred.createIndex()\n",
    "    # print(len(gt.getAnnIds()))\n",
    "    # print(len(pred.getAnnIds()))\n",
    "    # print(set([a['image_id'] for a in gt_anns]) - set([a['image_id'] for a in pred_anns]))\n",
    "    # print(gt_anns[0:10])\n",
    "    # print(pred_anns[0:10])\n",
    "    gt_eval = COCOeval(gt, pred, 'bbox')\n",
    "    gt_eval.params.imgIds = sorted(gt.getImgIds())\n",
    "    gt_eval.params.catIds = sorted(gt.getCatIds())\n",
    "    gt_eval.params.areaRng = [[0 ** 2, 1e10 ** 2]]\n",
    "    gt_eval.params.maxDets = [1, 10, 128]\n",
    "    gt_eval.params.areaRngLbl = ['all']\n",
    "    # gt_eval.params.iouThrs = [0.5]\n",
    "    gt_eval.params.useCats = 1\n",
    "    # for k, v in gt_eval.params.__dict__.items():\n",
    "    #     #Â check if v is an iterable\n",
    "    #     if hasattr(v, '__iter__'):\n",
    "    #         print(k, len(v), v[:10])\n",
    "    #     else:\n",
    "    #         print(k, v)\n",
    "    with contextlib.redirect_stdout(io.StringIO()):\n",
    "        gt_eval.evaluate()\n",
    "        gt_eval.accumulate()\n",
    "    # print(gt_eval.eval['precision'].shape)\n",
    "    # print(gt_eval.eval['precision'].reshape(-1))\n",
    "    # print(gt_eval.eval['recall'].reshape(-1))\n",
    "    # print(gt_eval.eval['scores'].reshape(-1))\n",
    "    return gt_eval.eval\n",
    "\n",
    "# def get_ious_ignore(gt_anns, pred_anns, imgs, cid):\n",
    "#     gt_iids = np.array([a['image_id'] for a in gt_anns]).astype(float)\n",
    "#     pred_iids = np.array([a['image_id'] for a in pred_anns]).astype(float)\n",
    "#     pred_scores = np.array([a['score'] for a in pred_anns]).astype(float)\n",
    "#     gt_bboxs = np.array([a['bbox'] for a in gt_anns]).astype(float)\n",
    "#     pred_bboxs = np.array([a['bbox'] for a in pred_anns]).astype(float)\n",
    "#     ious = mask_util.iou(pred_bboxs, gt_bboxs, [False] * len(gt_bboxs))\n",
    "#     valid_mask = (pred_iids[:, None] == gt_iids[None, :])\n",
    "#     print(ious.shape, valid_mask.shape)\n",
    "#     ious[~valid_mask] = -1.0\n",
    "#     inds = np.argsort(-pred_scores, kind=\"mergesort\")\n",
    "#     ious = ious[inds]\n",
    "#     max_iou_per_gt = ious.max(axis=0)\n",
    "#     max_iou_per_dt = ious.max(axis=1)\n",
    "#     argmax_iou_per_dt = ious.argmax(axis=1)\n",
    "#     found = set()\n",
    "#     keep_scores = []\n",
    "#     for iou, ind in zip(max_iou_per_gt, argmax_iou_per_dt):\n",
    "#         if iou > 0.5 and ind not in found:\n",
    "#             found.add(ind)\n",
    "#             keep_scores.append(pred_scores[ind])\n",
    "#         elif iou >\n",
    "        \n",
    "    \n",
    "#     return None, None\n",
    "\n",
    "\n",
    "\n",
    "def run_episode(inputs):\n",
    "    pred, gt, dino = inputs\n",
    "    \n",
    "    # print(\"gt keys:\", gt.keys())\n",
    "    # print(\"pred keys:\", pred.keys())\n",
    "    # print(\"gt response track keys:\", gt['response_track'][0].keys())\n",
    "    gt_fnos = [a['frame_number'] for a in gt['response_track']]\n",
    "    pred_fnos = [a['frame_number'] for a in pred['groundtruth_response_tracks']]\n",
    "    # print(len(pred['groundtruth_response_tracks']))\n",
    "    assert gt_fnos == pred_fnos\n",
    "    assert gt_fnos == list(range(min(gt_fnos), max(gt_fnos) + 1))\n",
    "    assert (gt['dataset_uid'] == pred['dataset_uid'])\n",
    "    # print(gt['query_frame'])\n",
    "    num_frames = gt['query_frame']\n",
    "    assert len(pred['predicted_bboxes']) == len(dino) == num_frames\n",
    "    # assert \n",
    "    num_valid_frames = gt['query_frame'] - min(gt_fnos)\n",
    "    # print(num_valid_frames)\n",
    "    # print(len(pred['predicted_peaks']))\n",
    "    valid_peaks = pred['predicted_peaks'][-num_valid_frames:]\n",
    "    valid_bboxes = pred['predicted_bboxes'][-num_valid_frames:]\n",
    "    valid_scores = pred['predicted_scores'][-num_valid_frames:]\n",
    "    valid_gt = pred['groundtruth_response_tracks'][-num_valid_frames:]\n",
    "    valid_dino = dino[-num_valid_frames:]\n",
    "    assert len(valid_peaks) == len(valid_bboxes) == len(valid_scores) == len(valid_dino), (len(valid_peaks), len(valid_bboxes), len(valid_scores), len(valid_dino))\n",
    "    # assert len(valid_peaks) == len(valid_bboxes) == len(valid_scores), (len(valid_peaks), len(valid_bboxes), len(valid_scores))\n",
    "    assert valid_gt[0]['frame_number'] == min(gt_fnos), (valid_gt[0]['frame_number'], min(gt_fnos))\n",
    "    \n",
    "    cid = int(gt['dataset_uid'].split(\"_\")[1]) + 1\n",
    "    gt_anns = construct_bboxes(valid_gt, cid, scores=None)\n",
    "    pred_anns = construct_bboxes(valid_bboxes, cid, scores=valid_scores, dino_scores=valid_dino, score_func=lambda x: np.sqrt(x[0] * x[1]), softmax_mul=0.0)\n",
    "    imgs = construct_imgs(valid_gt, num_valid_frames)\n",
    "    len_gt_anns = len(gt_anns)\n",
    "    len_pred_anns = len(pred_anns)\n",
    "    len_imgs = len(imgs)\n",
    "    min_gt_iid = min([a['image_id'] for a in gt_anns])\n",
    "    max_gt_iid = max([a['image_id'] for a in gt_anns])\n",
    "    min_pred_iid = min([a['image_id'] for a in pred_anns])\n",
    "    max_pred_iid = max([a['image_id'] for a in pred_anns])\n",
    "    min_img_iid = min([a['id'] for a in imgs])\n",
    "    max_img_iid = max([a['id'] for a in imgs])\n",
    "    assert min_gt_iid == min_pred_iid == min_img_iid\n",
    "    assert max_img_iid == max_pred_iid\n",
    "    assert len_gt_anns == max_gt_iid - min_gt_iid + 1, (len_gt_anns, max_gt_iid - min_gt_iid + 1)\n",
    "    # print(\"length of gt anns:\", len(gt_anns))\n",
    "    # print(\"length of pred anns:\", len(pred_anns))\n",
    "    # print(\"length of imgs:\", len(imgs))\n",
    "    # print(\"min gt_anns fno:\", min([a['image_id'] for a in gt_anns]))\n",
    "    # print(\"max gt_anns fno:\", max([a['image_id'] for a in gt_anns]))\n",
    "    # print(\"min pred_anns fno:\", min([a['image_id'] for a in pred_anns]))\n",
    "    # print(\"max pred_anns fno:\", max([a['image_id'] for a in pred_anns]))\n",
    "    # print(\"min imgs fno:\", min([a['id'] for a in imgs]))\n",
    "    # print(\"max imgs fno:\", max([a['id'] for a in imgs]))\n",
    "    # assert min([a['image_id'] for a in gt_anns]) == min([a['image_id'] for a in pred_anns]) == min([a['id'] for a in imgs])\n",
    "    # assert max([a['image_id'] for a in pred_anns]) == max([a['id'] for a in imgs])\n",
    "    # assert len(gt_anns) == len(imgs)\n",
    "\n",
    "    out_no_ignore = get_ious(gt_anns, pred_anns, imgs, cid)\n",
    "    del out_no_ignore['params']\n",
    "    out_no_ignore['dataset_uid'] = gt['dataset_uid']\n",
    "\n",
    "    return out_no_ignore\n",
    "    # for k, v in out_no_ignore.items():\n",
    "    #     if k in ['precision', 'recall', 'scores']:\n",
    "    #         print(k, v.shape)\n",
    "    # out_ignore, neg_frames = get_ious_ignore(gt_anns, pred_anns, imgs, cid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_outer_episode(i, duid2gt=None):\n",
    "    pred_path = PATH_TO_PREDS.format(i)\n",
    "    save_path = pred_path.replace(\".json.gz\", \"_pr_sc_dino_gmean.pkl\")\n",
    "    if os.path.exists(save_path):\n",
    "        return\n",
    "    dino_path = PATH_TO_DINO.format(i)\n",
    "    pred = preprocess_data(pred_path)\n",
    "    dino = preprocess_dino(dino_path)\n",
    "    duid2pred = {p['dataset_uid']: p for p in pred}\n",
    "    # duid2gt = {g['dataset_uid']: g for g in gt}\n",
    "    valid_duids = set([ann['dataset_uid'] for ann in duid2gt.values() if ann['clip_uid'] is not None])\n",
    "    duid2pred = {k: v for k, v in duid2pred.items() if k in valid_duids}\n",
    "    duid2gt = {k: v for k, v in duid2gt.items() if k in duid2pred.keys()}\n",
    "    duid2dino = {duid: dino[duid] for duid in duid2pred}\n",
    "    assert len(duid2pred) == len(duid2gt) == len(duid2dino)\n",
    "    inputs = [(duid2pred[k], duid2gt[k], duid2dino[k]) for k in sorted(duid2pred.keys())]\n",
    "    outputs = [run_episode(inp) for inp in inputs]\n",
    "    # save_path = pred_path.replace(\".json.gz\", \"_pr_dino_only.pkl\")\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        pickle.dump(outputs, f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199]\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "with open(\"/scratch/shared/beegfs/prannay/ego4d_data/ckpt/results/traces_v2_all/available_all.txt\", \"r\") as f:\n",
    "    available = f.read().splitlines()\n",
    "    available = sorted([int(a.split(\"_\")[3]) for a in available])\n",
    "print(available)\n",
    "print(len(available))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duid = list(duid2pred.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs_test = []\n",
    "# for duid in tqdm(sorted(duid2pred.keys()), total=len(duid2pred.keys())):\n",
    "#     output = run_episode((duid2pred[duid], duid2gt[duid], duid2dino[duid]))\n",
    "#     outputs_test.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = [(duid2pred[duid], duid2gt[duid]) for duid in sorted(duid2pred.keys())]\n",
    "# with Pool(32) as p:\n",
    "#     outputs = list(tqdm(p.imap_unordered(run_episode, inputs), total=len(inputs)))\n",
    "# # for duid in tqdm(sorted(duid2pred.keys())):\n",
    "# #     outputs.append(run_episode(duid2pred[duid], duid2gt[duid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f58606356d4466b7748c4956212f48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from functools import partial\n",
    "with open(PATH_TO_ANNS, \"r\") as f:\n",
    "    gt = json.load(f)\n",
    "duid2gt = {g['dataset_uid']: g for g in gt if g['clip_uid'] is not None}\n",
    "# try without Pool\n",
    "# outputs = []\n",
    "# for ind in tqdm(available, total=len(available)):\n",
    "#     run_outer_episode(ind, duid2gt=duid2gt)\n",
    "# try with Pool\n",
    "with Pool(16) as p:\n",
    "    _ = list(tqdm(p.imap_unordered(partial(run_outer_episode, duid2gt=duid2gt), available), total=len(available)))\n",
    "    # _ = list(tqdm(p.imap_unordered(partial(run_outer_episode, duid2gt=duid2gt), available), total=len(available)))\n",
    "# for i in tqdm(range(0, 1), total=1):\n",
    "    # run_outer_episode(i, duid2gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# PATH_TO_SAVE = \"/scratch/shared/beegfs/prannay/ego4d_data/ckpt/results/traces_v2_all/vq_pr_stats_val_all.pkl\"\n",
    "# with open(PATH_TO_SAVE, \"wb\") as f:\n",
    "#     pickle.dump(outputs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dinov2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

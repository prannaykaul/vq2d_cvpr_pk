{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import itertools\n",
    "import sys\n",
    "import json\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import pycocotools.mask as mask_util\n",
    "import io\n",
    "import contextlib\n",
    "from multiprocessing import Pool\n",
    "import pickle\n",
    "from scipy.stats import gmean\n",
    "from scipy.special import softmax\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_ANNS = \"../data/val_annot.json\"\n",
    "PATH_TO_PREDS = \"/scratch/shared/beegfs/prannay/ego4d_data/ckpt/results/traces_v2_all/vq_stats_val_{}.json.gz\"\n",
    "PATH_TO_DINO = \"/scratch/shared/beegfs/prannay/ego4d_data/ckpt/results/traces_v2_all/vq_stats_val_{}_dino_scores_all.pkl\"\n",
    "assert os.path.exists(PATH_TO_ANNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH_TO_ANNS, \"r\") as f:\n",
    "    anns = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED_IDXS = range(0, 200)\n",
    "path_to_preds = [PATH_TO_PREDS.format(i) for i in PRED_IDXS]\n",
    "assert all([os.path.exists(p) for p in path_to_preds])\n",
    "path_to_dinos = [PATH_TO_DINO.format(i) for i in PRED_IDXS]\n",
    "assert all([os.path.exists(p) for p in path_to_dinos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(path):\n",
    "    with gzip.open(path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    data = data['predictions']\n",
    "    # convert generic Dict[List] to List[Dict]\n",
    "    out_list = []\n",
    "    keys = sorted(data.keys())\n",
    "    for idx in range(len(data[keys[0]])):\n",
    "        save_dict = {k: data[k][idx] for k in keys}\n",
    "        save_dict['dataset_uid'] = save_dict['dataset_uids']\n",
    "        del save_dict['dataset_uids'] \n",
    "        out_list.append(save_dict)\n",
    "    return out_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dino(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        dino_data = pickle.load(f)\n",
    "    return dict(dino_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inner_episode(inputs):\n",
    "    pred, gt, dino = inputs\n",
    "    gt_fnos = [a['frame_number'] for a in gt['response_track']]\n",
    "    pred_fnos = [a['frame_number'] for a in pred['groundtruth_response_tracks']]\n",
    "    # print(len(pred['groundtruth_response_tracks']))\n",
    "    assert gt_fnos == pred_fnos\n",
    "    assert gt_fnos == list(range(min(gt_fnos), max(gt_fnos) + 1))\n",
    "    assert (gt['dataset_uid'] == pred['dataset_uid'])\n",
    "    # dino is a list\n",
    "    import pdb; pdb.set_trace()\n",
    "    gt_fnos = set(gt_fnos)\n",
    "    gt_list = defaultdict(dict)\n",
    "    assert len(dino) == len(pred['predicted_bboxes']) == len(pred['predicted_scores'])\n",
    "    for d, bb, sc in zip(dino, pred['predicted_bboxes'], pred['predicted_scores']):\n",
    "        if d['frame_number'] in gt_fnos:\n",
    "            gt_list.append((d['frame_number'], bb, sc, d['dino_scores']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_outer_episode(i, duid2gt=None):\n",
    "    pred_path = PATH_TO_PREDS.format(i)\n",
    "    dino_path = PATH_TO_DINO.format(i)\n",
    "    save_path = pred_path.replace(\".json.gz\", \"_sc_dino_gmean_gt_peak_tracker_init.json\")\n",
    "    if os.path.exists(save_path):\n",
    "        return\n",
    "    pred = preprocess_data(pred_path)\n",
    "    dino = preprocess_dino(dino_path)\n",
    "    duid2pred = {p['dataset_uid']: p for p in pred}\n",
    "    valid_duids = set([ann['dataset_uid'] for ann in duid2gt.values() if ann['clip_uid'] is not None])\n",
    "    duid2pred = {k: v for k, v in duid2pred.items() if k in valid_duids}\n",
    "    duid2gt = {k: v for k, v in duid2gt.items() if k in duid2pred.keys()}\n",
    "    duid2dino = {duid: dino[duid] for duid in duid2pred}\n",
    "    assert len(duid2pred) == len(duid2gt) == len(duid2dino)\n",
    "    inputs = [(duid2pred[k], duid2gt[k], duid2dino[k]) for k in sorted(duid2pred.keys())]\n",
    "    outputs = [run_inner_episode(inp) for inp in inputs]\n",
    "    with open(save_path, \"w\") as f:\n",
    "        json.dump(outputs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "None\n",
      "> \u001b[0;32m/tmp/ipykernel_66517/704524619.py\u001b[0m(10)\u001b[0;36mrun_inner_episode\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      6 \u001b[0;31m    \u001b[0;32massert\u001b[0m \u001b[0mgt_fnos\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpred_fnos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      7 \u001b[0;31m    \u001b[0;32massert\u001b[0m \u001b[0mgt_fnos\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_fnos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_fnos\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      8 \u001b[0;31m    \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset_uid'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset_uid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      9 \u001b[0;31m    \u001b[0;31m# dino is a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 10 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "[1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350]\n",
      "8\n",
      "1433\n",
      "1433\n",
      "1433\n",
      "1433\n",
      "1433\n",
      "\n",
      "1433\n",
      "1433\n",
      "1433\n"
     ]
    }
   ],
   "source": [
    "duid2gt = {g['dataset_uid']: g for g in anns if g['clip_uid'] is not None}\n",
    "run_outer_episode(0, duid2gt=duid2gt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vq2d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
